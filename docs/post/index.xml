<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on </title>
    <link>/post/</link>
    <description>Recent content in Posts on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Nov 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Stereograms of the 1KGP PCA/tSNE</title>
      <link>/2019/11/19/stereograms-1kgp-pca-tsne/</link>
      <pubDate>Tue, 19 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/11/19/stereograms-1kgp-pca-tsne/</guid>
      <description>What is stereoscopy? How to look at a stereogram?  Technique for creating or enhancing the illusion of depth in an image by means of stereopsis for binocular vision.
 –Stereoscopy (Wikipedia)
Although some binocular-like devices can be used to merge two images and create the illusion of depth, there are also “freeviewing” techniques that don’t require any particular material. The two main techniques are to either look straight through the image or to cross your eyes.</description>
    </item>
    
    <item>
      <title>Tweet network from Genome Informatics 2019</title>
      <link>/2019/11/10/gi2019-tweetnetwork/</link>
      <pubDate>Sun, 10 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/11/10/gi2019-tweetnetwork/</guid>
      <description>I want to have a quick look at the tweets from the Genome Informatics meeting:
 to learn how to use the rtweet and ggraph R packages. to create a visual representation (as nice as possible) of our open community, with attendants sharing with each other. to highlight the high-volume accounts and their value even for someone attending the conference. to see if there are sub-groups of researchers among the attendants.</description>
    </item>
    
    <item>
      <title>Workflow Description Language (WDL) in Emacs</title>
      <link>/2019/07/15/workflow-description-language-wdl-in-emacs/</link>
      <pubDate>Mon, 15 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/07/15/workflow-description-language-wdl-in-emacs/</guid>
      <description>wdl-mode poly-wdl Language Server Protocol Screenshots   I recently started working with WDL files. The Broad Institute recommends using Sublime and the syntax highlighter that they provide. They also provide a syntax highlighter for Vim. As Denis Loginov mentioned, they are working on an LSP implementation for WDL that could be used by tools to get syntax validation.
I looked first for a solution in Emacs, my go-to editor.</description>
    </item>
    
    <item>
      <title>Cancer genes and CNA hotspots</title>
      <link>/2019/04/03/cancer-genes-cna-r/</link>
      <pubDate>Wed, 03 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/04/03/cancer-genes-cna-r/</guid>
      <description>Candidate Cancer Gene Database (CCGD) Cancer Gene Census Merge the gene lists “Effect” vs “Role” ?  Known CNA hotspots Saving the R objects   This is an updated version of an old private post where I had prepared some R objects with cancer genes and CNA hotspots. I used this to quickly annotate copy number results in cancer projects. The file was almost 3 years old so here is an updated version (as of today, Apr 3 2019).</description>
    </item>
    
    <item>
      <title>First look at the gnomAD SV catalog</title>
      <link>/2019/03/31/gnomad-sv-first-look/</link>
      <pubDate>Sun, 31 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/03/31/gnomad-sv-first-look/</guid>
      <description>TL;DR SV types Detection methods Allele frequency Size distribution SV coordinates confusion Potential duplicates SV calling method Two size clusters of potentially duplicated complex variants Effect on allele frequency estimates  GiaB comparison to investigate sequence resolution CHR2 and END   Edit April 1 2019: I added columns with the proportion of variants with PASS filter in the tables about the END/POS confusion and duplicated variants.
Edit September 23 2019: Some tables (SV types, methods), investigation of the inconsistent CHR2/END for a few SVs.</description>
    </item>
    
    <item>
      <title>Artistic representation of DNA tests&#39; results</title>
      <link>/2018/12/08/dna-art/</link>
      <pubDate>Sat, 08 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/08/dna-art/</guid>
      <description>Version 1: Tree Version 2: Weave Version 3: Noise Version 4: Stars Gallery Code Notes   Christmas is coming. DNA tests are cool gifts but I’ve already offered it to some members of my family before. Now I was wondering if I could use this data in a more creative way and produce some kind of artistic representation of the DNA data to give them for Christmas. Some kind of DNA art or painting that would be unique.</description>
    </item>
    
    <item>
      <title>Speeding up blogdown/Pandoc for large bibliography</title>
      <link>/2018/11/17/speedup-blogwdown-pandoc-large-bibliography/</link>
      <pubDate>Sat, 17 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/11/17/speedup-blogwdown-pandoc-large-bibliography/</guid>
      <description>I have another website where I write down my reviews of the papers I read. To handle citations in pages and posts, I was originally using jekyll-scholar. It scales well enough that I could have one main BibTeX file for all the pages of the website. I’m now switching to blogdown/Hugo because it’s apparently faster, with less dependencies, but most importantly because it’s very easy to integrate R code with RMarkdown.</description>
    </item>
    
    <item>
      <title>The Formation of the Scientific Mind, Gaston Bachelard - part 1</title>
      <link>/2018/11/12/bachelard-formation-esprit-scientifique-part1/</link>
      <pubDate>Mon, 12 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/11/12/bachelard-formation-esprit-scientifique-part1/</guid>
      <description>Quotes about science The concept of epistemological obstacle The first obstacle: the primary experiment General knowledge as an obstacle An example of verbal obstacle: the sponge Aside on education Sick burns   These are notes from my reading of La formation de l’esprit scientifique by Gaston Bachelard. I hesitated a bit but finally decided to write the notes in English. In the end this blog is as much a place to save things I want to remember as a place to practice writing in English and share with other people.</description>
    </item>
    
    <item>
      <title>Peer-review opportunities for early career researchers</title>
      <link>/2018/11/07/ecr-peerreview/</link>
      <pubDate>Wed, 07 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/11/07/ecr-peerreview/</guid>
      <description>Some notes from today’s workshop organized by USPA with bio-protocol and eLife ambassadors.
Bio-protocol Data is uploaded to databases, code to repos like GitHub but protocols are still just in the Methods section of papers. And the Methods of a paper often omits many details which makes it difficult to reuse the experiment or reproduce results.
Dennis Bua introduced bio-protocol, a platform to peer-review protocols. Here the goal is to make sure all the information is provided to reproduce an experiment.</description>
    </item>
    
    <item>
      <title>Syncing Mendeley and PDFs across devices</title>
      <link>/2018/09/22/sync-mendeley/</link>
      <pubDate>Sat, 22 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/22/sync-mendeley/</guid>
      <description>20 March 2019 Edit: I switched to Zotero (yeay open-source, bye Elsevier), using Google Drive to store the PDF files. See the Internet section and the blog post that inspired the change.
Recently, I’ve been setting up new computers from scratch as I moved from Montreal to Santa Cruz. Like for spring cleaning, it might be a good idea to clarify the system I’ve been using to manage bibliography and PDF annotation.</description>
    </item>
    
    <item>
      <title>Mental health crisis in science...but careful with nonresponse bias</title>
      <link>/2018/07/08/mental-health-crisis-science/</link>
      <pubDate>Sun, 08 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/07/08/mental-health-crisis-science/</guid>
      <description>A few month ago, a short paper was published in Nature Biotechnology1 about the mental health crisis in science. It attracted a bit of attention on the news and social media, which is good because it’s an important matter. The article was very good at putting the subject on the table and proposing some solutions, but it picked my curiosity about nonresponse bias.
Issues with the Nature Biotech article The numbers are based on an email survey so one issue is the nonresponse bias: the individuals that responded might not be representative of the population.</description>
    </item>
    
    <item>
      <title>Clustering into same size clusters</title>
      <link>/2018/06/09/cluster-same-size/</link>
      <pubDate>Sat, 09 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/06/09/cluster-same-size/</guid>
      <description>Methods Iterative dichotomy Iterative nearest neighbor Same-size k-Means Variation Iterative “bottom-leaves” hierarchical clustering  Test data Results Cluster size Within-cluster distance Silhouette score  Conclusions Extra: optimization Code   Update Nov 23 2018: New iterative approach using hierarchical clustering and better graphs.
I would like to cluster points into groups of similar size. For example I would like to group 1000 points into clusters of around 20 points each.</description>
    </item>
    
    <item>
      <title>Converting scientific reviews to EPUB</title>
      <link>/2018/05/07/epub-reviews/</link>
      <pubDate>Mon, 07 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/05/07/epub-reviews/</guid>
      <description>First, check on PubMed Central Convert the HTML page to EPUB Clean up the HTML before conversion  Compiling several reviews into one EPUB document VPN, paywall and Pandoc Limitations Methods  Other EPUB resources Loose Ends by Sidney Brenner   Edit Apr 6 2019: Added the compilation of Loose Ends columns by Sidney Brenner.
Third post on the series of “Things I did instead of writing my thesis to help me write my thesis”: how to find/convert reviews in the EPUB format to read in an ebook reader.</description>
    </item>
    
    <item>
      <title>Additional checks for a LaTeX manuscript</title>
      <link>/2018/04/18/check-latex-pub/</link>
      <pubDate>Wed, 18 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/18/check-latex-pub/</guid>
      <description>To continue on the series of “Things I did instead of writing my thesis to help me write my thesis”, another Python script that reads a LaTeX manuscript and helps check that everything is fine. More specifically, the checkLatex.py script (on GitHub) will:
List missing references. List multi-references to reorder. List duplicated labels. List labels that don’t start by fig: or tab:. List figures/tables that are not in order. List ?</description>
    </item>
    
    <item>
      <title>Checking text similarity between two documents</title>
      <link>/2018/04/16/text-similarity/</link>
      <pubDate>Mon, 16 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/16/text-similarity/</guid>
      <description>To start the series of “Things I did instead of writing my thesis to help me write my thesis”, a small Python script that compares two text documents and output similar parts. I did that to avoid auto-plagiarism of my manuscripts’ introduction in the main thesis introduction.
It’s a very naive approach but sped up the checking process (maybe worth the time). It first looks for short exact matches between the two documents, then extends these exact matches and uses the difflib module to keep text with a minimum similarity score (default 80%).</description>
    </item>
    
    <item>
      <title>Journal comparison</title>
      <link>/2018/02/23/journals-comparison/</link>
      <pubDate>Fri, 23 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/02/23/journals-comparison/</guid>
      <description>Edit Feb 24: Added variance graph and some examples of suspiciously fast publications.
Edit Feb 25: Added script and data to GitHub.
Some info about journals in my field.
Summary table   Journal Co. IF OA APC Other fees Pub/year Received-to-accepted in days. median (75th perc.)    F1000Research - 1.2 Y 1000 USD -    PeerJ - 2.2 Y 1095 USD - ~1290 ~88 (139)  eLife - 7.</description>
    </item>
    
    <item>
      <title>tSNE and clustering</title>
      <link>/2018/02/13/tsne-and-clustering/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/02/13/tsne-and-clustering/</guid>
      <description>tSNE can give really nice results when we want to visualize many groups of multi-dimensional points. Once the 2D graph is done we might want to identify which points cluster in the tSNE blobs.
Using simulated and real data, I’ll try different methods:
 Hierarchical clustering K-means Gaussian mixture Density-based clustering Louvain community detection.  TL;DR If &amp;lt;30K points, hierarchical clustering is robust, easy to use and with reasonable computing time.</description>
    </item>
    
    <item>
      <title>Bibliography style for AJHG</title>
      <link>/2017/10/04/bibliography-style-for-ajhg/</link>
      <pubDate>Wed, 04 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/10/04/bibliography-style-for-ajhg/</guid>
      <description>I couldn’t find an up-to-date/working LaTeX bibliography style for the American Journal of Human Genetics (AJHG). The output from unsrtnat (my goto style) was also quite different from what the journal wanted.
I found a bibliography style for Cell which is almost what AJHG wants, but I also wanted the references to be ordered by their appearance in the text (like for unsrtnat) and not alphabetically. So I downloaded both cell.</description>
    </item>
    
    <item>
      <title>MUMmerplots with ggplot2</title>
      <link>/2017/09/19/mummerplots-with-ggplot2/</link>
      <pubDate>Tue, 19 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/09/19/mummerplots-with-ggplot2/</guid>
      <description>Update Oct 28 2018: added reference id (rid) to be able to visualize multiple reference regions. Also uploaded the example data somewhere.
library(dplyr) library(magrittr) library(GenomicRanges) library(knitr) library(ggplot2) library(tidyr) MUMmer plot The MUMmer plot that I want to reproduce showed three contigs overlapping a region of chr 14. I had filtered the delta file with delta-filter -l 10000 -q -r to get only the contigs with the best alignments. I had used mummerplot with the -l layout option to reorder and orient the sequences to have a nice diagonal.</description>
    </item>
    
    <item>
      <title>Regression sandbox</title>
      <link>/2017/09/16/regression-sandbox/</link>
      <pubDate>Sat, 16 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/09/16/regression-sandbox/</guid>
      <description>library(ggplot2) library(broom) library(magrittr) library(dplyr) library(knitr) Logistic regression One way or another If we have two binary variables and we want to see if they are associated we could use a logistic regression. How do we decide which variable to be the predictor and which variable to observed variable ?
In theory there shouldn’t be any differences but let’s check with a dummy example:
df = data.frame(x = sample(c(FALSE, TRUE), 100, TRUE)) df$y = df$x df$y[1:70] = sample(c(FALSE, TRUE), 70, TRUE) glm(y ~ x, data = df, family = binomial()) %&amp;gt;% tidy %&amp;gt;% kable   term estimate std.</description>
    </item>
    
    <item>
      <title>Enrichment between genomic regions</title>
      <link>/2017/09/05/enrichment-between-genomic-regions/</link>
      <pubDate>Tue, 05 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/09/05/enrichment-between-genomic-regions/</guid>
      <description>Testing if two sets of genomic regions overlap significantly is not straightforward. In the simple situation of regions of 1 bp (e.g. SNVs) we could use a hypergeometric test. When the regions are small enough and there are not too many, the hypergeometric test might also be a fair approximation.
But when we manipulate many regions of variable size covering the entire genome it’s not as straightforward. The gene annotation is an example.</description>
    </item>
    
    <item>
      <title>Conservation to annotate large(r) regions</title>
      <link>/2017/02/25/conservation-to-annotate-larger-regions/</link>
      <pubDate>Sat, 25 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/02/25/conservation-to-annotate-larger-regions/</guid>
      <description>Conservation can be used to annotate single nucleotide changes or short variants. This information helps assessing the functional impact of short variation.
What if we have larger variants, for example deletions larger than 50 bp, or larger than 1 kbp. Can we use conservation metrics? In this case the question is often not “Is the region conserved?” but rather “Is there any conserved elements in the region?”.
One approach would be to overlap the variants/deletions with known (ultra-)conserved regions.</description>
    </item>
    
    <item>
      <title>Segmental duplication exploration</title>
      <link>/2016/10/20/segmental-duplication-exploration/</link>
      <pubDate>Thu, 20 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/10/20/segmental-duplication-exploration/</guid>
      <description>Segmental Duplications (SD) I downloaded the segmental duplication annotation for hg19 from UCSC. There are 51599 annotated SD. They are defined as regions larger than 1 Kbp with at least 90% similarity with another region in the genome.
 Segmental duplication regions Many SD are nested of located next to each other. I merge overlapping SDs (or located at &amp;lt;10 bp) to create SD regions, i.e. longer stretch of the genome overlapping SDs.</description>
    </item>
    
    <item>
      <title>Summary epigenetic mark tracks</title>
      <link>/2016/09/06/summary-epigenetic-mark-tracks/</link>
      <pubDate>Tue, 06 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/09/06/summary-epigenetic-mark-tracks/</guid>
      <description>To assess the potential impact of variants (SNV, SVs) we might want to use some of the public epigentic datasets. The amount and heterogeneity of this data is a bit overwhelming. I would like to get a summary of which regions of the genome are the most functionally important.
The plan is to:
 get annotated peaks for the 6 typical histone marks in 5-6 tissues, merging sub-tissues (e.g. brain subregions) keep regions supported by enough replicates  Eventually, I could also annotate the regions that are tissue-specific or shared across tissues.</description>
    </item>
    
    <item>
      <title>Exploring basic annotations of the Human genome</title>
      <link>/2016/06/04/exploring-basic-annotations-of-the-human-genome/</link>
      <pubDate>Sat, 04 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/06/04/exploring-basic-annotations-of-the-human-genome/</guid>
      <description>Quick look at the annotations Genes In Gencode V19 and focusing on autosomes/X/Y, there are 57783 “genes” of different types:
  type n    protein_coding 20,332  pseudogene 13,931  lincRNA 7,114  antisense 5,276  miRNA 3,055  misc_RNA 2,034  snRNA 1,916  snoRNA 1,457  sense_intronic 742  rRNA 527  processed_transcript 515  sense_overlapping 202  IG_V_pseudogene 187  IG_V_gene 138  TR_V_gene 97  TR_J_gene 74  polymorphic_pseudogene 45  IG_D_gene 37  TR_V_pseudogene 27  3prime_overlapping_ncrna 21  IG_J_gene 18  IG_C_gene 14  IG_C_pseudogene 9  TR_C_gene 5  TR_J_pseudogene 4  IG_J_pseudogene 3  TR_D_gene 3     Exons In Gencode V19 and focusing on autosomes/X/Y, there are 1196256 “exons” from different types of genes:</description>
    </item>
    
    <item>
      <title>Gencode exploration</title>
      <link>/2016/06/04/gencode-exploration/</link>
      <pubDate>Sat, 04 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/06/04/gencode-exploration/</guid>
      <description>Gencode v19 I downloaded Gencode v19 at ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_19/gencode.v19.annotation.gtf.gz.
 Genes Number Focusing on autosomes/X/Y, there are 57,783 “genes” of different types:
I merge the rare types into a other class and some RNAs.
  gene_type.f n    protein_coding 20332  pseudogene 13931  other 7417  lincRNA 7114  RNA 5934  miRNA 3055     Size The largest annotated genes span more than 2 Mbp:</description>
    </item>
    
    <item>
      <title>Preparing some genomic annotations</title>
      <link>/2016/06/03/preparing-some-genomic-annotations/</link>
      <pubDate>Fri, 03 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/06/03/preparing-some-genomic-annotations/</guid>
      <description>Mappability track I produced a mappability track from the UCSC track. The raw file contains, for each base in the genome, an estimation of the probability that a read is correctly mapped at this position.
Using a sliding-window approach, I compute the average mappability in regions of size 1 Kbp. This is a more manageable amount of data and still informative, especially when interested in large regions (e.g. SVs).</description>
    </item>
    
    <item>
      <title>Word Cloud in R</title>
      <link>/2016/02/26/word-cloud-in-r/</link>
      <pubDate>Fri, 26 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/02/26/word-cloud-in-r/</guid>
      <description>The wordcloud package is available on CRAN.
Fake words I create fake words to see a bit how the command is working.
library(wordcloud) createWords &amp;lt;- function(w.l = 3) paste(sample(letters, w.l, TRUE), collapse = &amp;quot;&amp;quot;) words = sapply(1:200, function(e) createWords(runif(1, 3, 10))) freq = c(sample(1:30, 190, T), sample(30:150, 10, T)) freq = freq/sum(freq) wordcloud(words, freq) ## Big words in the center wordcloud(words, freq, random.order = FALSE) ## Max word number wordcloud(words, freq, max.</description>
    </item>
    
  </channel>
</rss>